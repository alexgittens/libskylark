{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libSkylark in SoftLayer Cloud\n",
    "**Running MPI computations over IBM SoftLayer cloud clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We detail the steps to take to:\n",
    "\n",
    "- launch a cluster of virtual server instances in IBM SoftLayer cloud\n",
    "\n",
    "- run parallel, MPI-based, computations with libSkylark over this cluster\n",
    "\n",
    "Examples of interactive parallel computations on this cloud cluster are also explored.\n",
    "\n",
    "With a starting cost of `$0.04`/hour/server - this is the default in our configuration - one needs to spend `$0.12` for an one-hour single launch of the 3-machine cluster we are assembling below and play with the suggested setup and examples.\n",
    "\n",
    "All steps can be conveniently performed in our laptop browser connected to local and remote jupyter notebook servers.\n",
    "\n",
    "So, let's get started!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBM SoftLayer credentials\n",
    "\n",
    "When you open a SoftLayer account you get an IBMid and you use this together with a password to access your dashboard portal though https://control.softlayer.com. This portal has all the details for your current and past purcases (devices, storage, etc), charging and account information, etc, also allowing you to buy new resources, cancel existing ones, etc. \n",
    "\n",
    "So, you go to Account > Users in the portal and you retrieve just two pieces of information from there:\n",
    "\n",
    "- your `username`, typically a short alphanumeric starting with SL\n",
    "- your `api_key`, typically a very long alphanumeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't want to share this information with others(!!) but you definitely want to make it available to some of the python snippets in this session. One way for not including this information in the notebook is to populate two environment variables (and the python snippets will by default recover these values from there), e.g. in `bash`:\n",
    "```\n",
    "export SL_USERNAME=<your username>\n",
    "export SL_API_KEY=<you api_key>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common theme in cloud computing services is to make their API callable in the browser: A user constructs a long url essentially embedding his credentials and what service he wants and makes an https request. The answer that gets back is typically in the form of a json or xml string. On top of these, people build lightweight wrappers for many languages, all of which basically assemble the url, do the https request and parse the string that comes back.\n",
    "\n",
    "IBM SoftLayer provides python bindings of the underlying XMLRPC API in a package called `SoftLayer`. We install it, also make sure that `paramiko` is also installed - this is a python ssh client -  and import these together with a 2-3 more or less standard packages for what follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import SoftLayer\n",
    "import paramiko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cStringIO as StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BTW, we can now confirm that the SoftLayer credentials are there for the `SoftLayer` API to fish, e.g.:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SL1193343'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['SL_USERNAME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching the machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental object in `SoftLayer` is the `Client`. Let's make one and then construct a `VSManager` object through which we are going to launch our virtual server instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = SoftLayer.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vs_manager = SoftLayer.VSManager(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a description of the characteristics of the virtual server instances we plan to launch. Things like:\n",
    "- Where do we need these to be physically located (i.e. what datacenter)? This could be important if we need to upload to or download from these machines huge datasets with very strict latency constraints. \n",
    "- What is the domain to put these machines in?\n",
    "- How many cpus?\n",
    "- What is the RAM of the machines?\n",
    "- Is charging applied on a per hour basis?\n",
    "- What operating system these machine will have?\n",
    "- Available local disks?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vs_descriptor_base = {'datacenter' : {'name' : 'tor01'},\n",
    "                      'domain': 'skylark.com',\n",
    "                      'startCpus': 1,\n",
    "                      'maxMemory': 1024,\n",
    "                      'hourlyBillingFlag': 'true',\n",
    "                      'operatingSystemReferenceCode': 'UBUNTU_14_64',\n",
    "                      'localDiskFlag': 'false'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plan for launching servers at Toronto datacenter, put them under `skylark.com` - a dummy setting actually for our scenario since we do not further tweak DNS - each with **1 cpu and 1 GB of RAM with Ubuntu 14.04 preinstalled**. Hourly billing and no local disks are also typical or minimal options, however good for our purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll launch 3 nodes (i.e. 3 virtual server instances). One of them will be the server of the NFS shared folder and the other 2 will be the NFS clients, thus the names. We also assign these machines the short hostnames `node00`, `node01` and `node02`, update their descriptions and look into print one of them and also to the lists of short hostnames (`server_name`, `client_names`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_nodes  = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodename_list = ['node%02d' % i for i in range(num_nodes)]\n",
    "server_name  = nodename_list[0]\n",
    "client_names = nodename_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vs_descriptor_dict = {}\n",
    "for nodename in nodename_list:\n",
    "    vs_descriptor = vs_descriptor_base.copy()\n",
    "    vs_descriptor.update({'hostname' : nodename})\n",
    "    vs_descriptor_dict[nodename] = vs_descriptor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datacenter': {'name': 'tor01'},\n",
       " 'domain': 'skylark.com',\n",
       " 'hostname': 'node00',\n",
       " 'hourlyBillingFlag': 'true',\n",
       " 'localDiskFlag': 'false',\n",
       " 'maxMemory': 1024,\n",
       " 'operatingSystemReferenceCode': 'UBUNTU_14_64',\n",
       " 'startCpus': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs_descriptor_dict['node00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'node00'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['node01', 'node02']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, everything is setup for launching our machines (and thus start charging ourselves!). We collect the handles into the launch requests (asynchronously executing remotely at Toronto) in a dictionary keyed by the short hostnames..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vsi_dict = {}\n",
    "vsi_dict[server_name] = client['Virtual_Guest'].createObject(vs_descriptor_dict[server_name])\n",
    "\n",
    "for client_name in client_names:\n",
    "    vsi_dict[client_name] = client['Virtual_Guest'].createObject(\n",
    "        vs_descriptor_dict[client_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and enter a polling loop, which when finished will basically tell us that our Toronto machines are ready to be accessed and used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ready = [False] * num_nodes\n",
    "while not np.all(ready):\n",
    "    for i, nodename in enumerate(nodename_list):\n",
    "        ready[i] = vs_manager.wait_for_ready(vsi_dict[nodename]['id'], \n",
    "                                         limit=10, delay=1, pending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can take something between 5-10 mins for these 3 machines to come to life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting ready for setting up the cloud cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK... Now we are ready to `ssh` into these machines and start working. For `ssh`ing we need the username (default: `root`), the password and the public IP that has been assigned to each of our machines. Let's collect them in a dictionary and have them handy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "credential_dict = {}\n",
    "for nodename in nodename_list:\n",
    "    vsi                = vs_manager.get_instance(vsi_dict[nodename]['id'])\n",
    "    username           = vsi['operatingSystem']['passwords'][0]['username']\n",
    "    password           = vsi['operatingSystem']['passwords'][0]['password']\n",
    "    primary_ip_address = vsi['primaryIpAddress']\n",
    "    vsi_dict[nodename] = vsi\n",
    "    credential_dict[nodename] = {'username' : username, \n",
    "                                 'password' : password,\n",
    "                                 'primary_ip_address' : primary_ip_address}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node00': {'password': 'JaTCH8T8',\n",
       "  'primary_ip_address': '169.55.169.150',\n",
       "  'username': 'root'},\n",
       " 'node01': {'password': 'DpgUDHc5',\n",
       "  'primary_ip_address': '169.55.169.147',\n",
       "  'username': 'root'},\n",
       " 'node02': {'password': 'M4BZdT6s',\n",
       "  'primary_ip_address': '169.55.169.148',\n",
       "  'username': 'root'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credential_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure that each machine knows the IPs of the others and has some proper mnemonics (names) for them. This resolving can be served by `/etc/hosts` which we'll append to later. So let's cook up what to append, now that we know all relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169.55.169.148\tnode02.skylark.com\tnode02\n",
      "169.55.169.150\tnode00.skylark.com\tnode00\n",
      "169.55.169.147\tnode01.skylark.com\tnode01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = StringIO.StringIO()\n",
    "domain = vs_descriptor_base['domain']\n",
    "for key, value in credential_dict.iteritems():\n",
    "    hostname = key\n",
    "    full_hostname = '%s.%s' % (hostname, domain)\n",
    "    primary_ip_address = value['primary_ip_address']\n",
    "    print >> f, '%s\\t%s\\t%s' % (primary_ip_address, full_hostname, hostname)\n",
    "etc_hosts_fragment = f.getvalue()\n",
    "f.close()\n",
    "print etc_hosts_fragment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our method of automatically installing all necessary software to turn the **bunch of generic machines** we get from the IBM SoftLayer launch to a **cluster of machines ready to run MPI computations with libSkylark** is pretty simple but effective:\n",
    "\n",
    "- List the commands we need to run with root privileges and the commands we need to run with a normal user privileges\n",
    "\n",
    "- Script ssh sessions to each of the machines for automating the execution of these commands\n",
    "\n",
    "In this context it makes sense to actually splice some parameters in these command lists/templates - for flexiblity purposes. We collect these parameters here: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmd_params = {\n",
    "    'etc_hosts_fragment' : etc_hosts_fragment,\n",
    "    'shared_folder' : '/shared',\n",
    "    'user_name' : 'user',\n",
    "    'user_password' : 'user',\n",
    "    'gecos' : 'user',\n",
    "    'miniconda_url' : 'https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh',\n",
    "    'miniconda_filename' : 'Miniconda2-latest-Linux-x86_64.sh',\n",
    "    'channel_url' : 'https://github.com/xdata-skylark/libskylark/releases/download/v0.20/channel.tar.gz',\n",
    "    'channel_filename' : 'channel.tar.gz'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can put together the individual command template sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we need to execute as `root` at the (NFS) server node?\n",
    "\n",
    "- install NFS server software\n",
    "- install an editor of our choice, here emacs\n",
    "- export the folder to share with all nodes\n",
    "- add a \"normal user\" with its home being this exported folder\n",
    "- update '/etc/hosts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server_root_setup_cmd_template_list = [\n",
    "    'apt-get update',\n",
    "    'apt-get install -y openssh-server',\n",
    "    'apt-get install -y nfs-server', \n",
    "    'apt-get install -y emacs',\n",
    "    'mkdir %(shared_folder)s',\n",
    "    'echo \"%(shared_folder)s *(rw,sync)\" | tee -a /etc/exports',\n",
    "    'service nfs-kernel-server restart', \n",
    "    'adduser --home %(shared_folder)s --uid 1100 --gecos %(gecos)s --disabled-password %(user_name)s',\n",
    "    'echo \"%(user_name)s:%(user_password)s\" | chpasswd',\n",
    "    'chown %(user_name)s %(shared_folder)s',\n",
    "    'echo -ne \"%(etc_hosts_fragment)s\" >> /etc/hosts'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we need to execute as \"normal user\" at the (NFS) client node?\n",
    "\n",
    "- generate a (public, private) ssh key pair in order to allow password-less ssh login\n",
    "- install libSkylark which consists of the following steps:\n",
    " - install miniconda2 (i.e. miniconda for python 2.7.xx)\n",
    " - download the conda channel with libSkylark dependencies (i.e. tarballs of prebuilt binaries)\n",
    " - install fftw conda package (from conda-forge repo) and libskylark from the conda channel\n",
    " - update PATH and LD_LIBRARY_PATH environment variables and make sure these are exported at ssh login time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server_user_setup_cmd_template_list = [\n",
    "    'cat /dev/zero | ssh-keygen -t rsa -q -N \"\" > /dev/null',\n",
    "    'cd .ssh',\n",
    "    'cat id_rsa.pub >> authorized_keys',\n",
    "    'cd ${HOME}',\n",
    "    'curl -L -O %(miniconda_url)s',\n",
    "    'bash %(miniconda_filename)s -b -p ${HOME}/miniconda2',\n",
    "    'curl -L -O %(channel_url)s',\n",
    "    'tar -xvzf %(channel_filename)s',\n",
    "    'export PATH=${HOME}/miniconda2/bin:${PATH}',\n",
    "    'conda install fftw --yes --channel conda-forge',\n",
    "    'conda install libskylark --yes --channel file://${HOME}/channel',\n",
    "    'echo \"export PATH=${PATH}\" >> ${HOME}/.bashrc',\n",
    "    'echo \"export LD_LIBRARY_PATH=${HOME}/miniconda2/lib:${LD_LIBRARY_PATH}\" >> ${HOME}/.bashrc',\n",
    "    'echo \"export LD_LIBRARY_PATH=${HOME}/miniconda2/lib64:${LD_LIBRARY_PATH}\" >> ${HOME}/.bashrc',\n",
    "    'echo \"[[ -f ${HOME}/.bashrc ]] && . ${HOME}/.bashrc\" >> ${HOME}/.bash_profile'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we need to execute as `root` at the (NFS) client nodes?\n",
    "\n",
    "- install NFS client software\n",
    "- install an editor of our choice, here emacs\n",
    "- mount the folder exported by the (NFS) server node\n",
    "- add a \"normal user\" with its home being this mounted folder\n",
    "- update '/etc/hosts'\n",
    "\n",
    "No further commands need to be executed as a \"normal user\" at the (NFS) client nodes, because related settings (installs, environment variables) have already been configured at the (NFS) server node and have been shared with all nodes through the exported folder, which also serves as the \"home\" of this user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client_root_setup_cmd_template_list = [\n",
    "    'apt-get update',\n",
    "    'apt-get install -y openssh-server',\n",
    "    'apt-get install -y nfs-client',\n",
    "    'apt-get install -y emacs',\n",
    "    'mkdir %(shared_folder)s',\n",
    "    'mount %(server_ip)s:%(shared_folder)s %(shared_folder)s',\n",
    "    'adduser --home %(shared_folder)s --uid 1100 --gecos %(gecos)s --disabled-password %(user_name)s',\n",
    "    'echo \"%(user_name)s:%(user_password)s\" | chpasswd',\n",
    "    'echo -ne \"%(etc_hosts_fragment)s\" >> /etc/hosts'\n",
    "]\n",
    "\n",
    "client_user_setup_cmd_template_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the command parameters setup we update with the public ip of the (NFS) server machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmd_params.update({'server_ip' : \n",
    "                   credential_dict[server_name]['primary_ip_address']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the command parameters look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel_filename': 'channel.tar.gz',\n",
       " 'channel_url': 'https://github.com/xdata-skylark/libskylark/releases/download/v0.20/channel.tar.gz',\n",
       " 'etc_hosts_fragment': '169.55.169.148\\tnode02.skylark.com\\tnode02\\n169.55.169.150\\tnode00.skylark.com\\tnode00\\n169.55.169.147\\tnode01.skylark.com\\tnode01\\n',\n",
       " 'gecos': 'user',\n",
       " 'miniconda_filename': 'Miniconda2-latest-Linux-x86_64.sh',\n",
       " 'miniconda_url': 'https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh',\n",
       " 'server_ip': '169.55.169.150',\n",
       " 'shared_folder': '/shared',\n",
       " 'user_name': 'user',\n",
       " 'user_password': 'user'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We splice the parameters into the command templates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "server_root_setup_cmd = '; '.join(server_root_setup_cmd_template_list) % cmd_params\n",
    "server_user_setup_cmd = '; '.join(server_user_setup_cmd_template_list) % cmd_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client_root_setup_cmd = '; '.join(client_root_setup_cmd_template_list) % cmd_params\n",
    "client_user_setup_cmd = '; '.join(client_user_setup_cmd_template_list) % cmd_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also briefly inspect the command strings that are to be executed at the newly launched nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apt-get update; apt-get install -y openssh-server; apt-get install -y nfs-server; apt-get install -y emacs; mkdir /shared; echo \"/shared *(rw,sync)\" | tee -a /etc/exports; service nfs-kernel-server restart; adduser --home /shared --uid 1100 --gecos user --disabled-password user; echo \"user:user\" | chpasswd; chown user /shared; echo -ne \"169.55.169.148\\tnode02.skylark.com\\tnode02\\n169.55.169.150\\tnode00.skylark.com\\tnode00\\n169.55.169.147\\tnode01.skylark.com\\tnode01\\n\" >> /etc/hosts'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_root_setup_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat /dev/zero | ssh-keygen -t rsa -q -N \"\" > /dev/null; cd .ssh; cat id_rsa.pub >> authorized_keys; cd ${HOME}; curl -L -O https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh; bash Miniconda2-latest-Linux-x86_64.sh -b -p ${HOME}/miniconda2; curl -L -O https://github.com/xdata-skylark/libskylark/releases/download/v0.20/channel.tar.gz; tar -xvzf channel.tar.gz; export PATH=${HOME}/miniconda2/bin:${PATH}; conda install fftw --yes --channel conda-forge; conda install libskylark --yes --channel file://${HOME}/channel; echo \"export PATH=${PATH}\" >> ${HOME}/.bashrc; echo \"export LD_LIBRARY_PATH=${HOME}/miniconda2/lib:${LD_LIBRARY_PATH}\" >> ${HOME}/.bashrc; echo \"export LD_LIBRARY_PATH=${HOME}/miniconda2/lib64:${LD_LIBRARY_PATH}\" >> ${HOME}/.bashrc; echo \"[[ -f ${HOME}/.bashrc ]] && . ${HOME}/.bashrc\" >> ${HOME}/.bash_profile'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_user_setup_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apt-get update; apt-get install -y openssh-server; apt-get install -y nfs-client; apt-get install -y emacs; mkdir /shared; mount 169.55.169.150:/shared /shared; adduser --home /shared --uid 1100 --gecos user --disabled-password user; echo \"user:user\" | chpasswd; echo -ne \"169.55.169.148\\tnode02.skylark.com\\tnode02\\n169.55.169.150\\tnode00.skylark.com\\tnode00\\n169.55.169.147\\tnode01.skylark.com\\tnode01\\n\" >> /etc/hosts'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_root_setup_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_user_setup_cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the cloud cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are ready to execute our crafted setup commands by `ssh`-ing into the (NFS) client and server machines as `root` and \"normal user\"s and running the commands. We automate this process by scripting those `ssh` sessions. Also for convenient reference we capture the `stdout` and `stderr` streams of the setup commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setup_streams = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# server\n",
    "hostname = server_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# server root\n",
    "cmd = server_root_setup_cmd\n",
    "ssh = paramiko.SSHClient()\n",
    "ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "ssh.connect(credential_dict[hostname]['primary_ip_address'], \n",
    "            username=credential_dict[hostname]['username'], \n",
    "            password=credential_dict[hostname]['password'])\n",
    "stdin, stdout, stderr = ssh.exec_command(cmd)\n",
    "stdout_lines = stdout.readlines()\n",
    "stderr_lines = stderr.readlines()\n",
    "primary_ip_address = credential_dict[hostname]['primary_ip_address']\n",
    "setup_streams[primary_ip_address] = {'root' : {}}\n",
    "setup_streams[primary_ip_address]['root']['stdout'] = ''.join(stdout_lines)\n",
    "setup_streams[primary_ip_address]['root']['stderr'] = ''.join(stderr_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# server user\n",
    "cmd = server_user_setup_cmd\n",
    "ssh = paramiko.SSHClient()\n",
    "ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "ssh.connect(credential_dict[hostname]['primary_ip_address'], \n",
    "            username=cmd_params['user_name'], \n",
    "            password=cmd_params['user_password'])\n",
    "stdin, stdout, stderr = ssh.exec_command(cmd)\n",
    "stdout_lines = stdout.readlines()\n",
    "stderr_lines = stderr.readlines()\n",
    "primary_ip_address = credential_dict[hostname]['primary_ip_address']\n",
    "setup_streams[primary_ip_address]['user'] = {}\n",
    "setup_streams[primary_ip_address]['user']['stdout'] = ''.join(stdout_lines)\n",
    "setup_streams[primary_ip_address]['user']['stderr'] = ''.join(stderr_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# client root\n",
    "cmd = client_root_setup_cmd\n",
    "ssh = paramiko.SSHClient()\n",
    "ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "for hostname in client_names:\n",
    "    ssh.connect(credential_dict[hostname]['primary_ip_address'], \n",
    "            username=credential_dict[hostname]['username'], \n",
    "            password=credential_dict[hostname]['password'])\n",
    "    stdin, stdout, stderr = ssh.exec_command(cmd)\n",
    "    stdout_lines = stdout.readlines()\n",
    "    stderr_lines = stderr.readlines()\n",
    "    primary_ip_address = credential_dict[hostname]['primary_ip_address']\n",
    "    setup_streams[primary_ip_address] = {'root' : {}}\n",
    "    setup_streams[primary_ip_address]['root']['stdout'] = ''.join(stdout_lines)\n",
    "    setup_streams[primary_ip_address]['root']['stderr'] = ''.join(stderr_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# client user\n",
    "cmd = client_user_setup_cmd\n",
    "ssh = paramiko.SSHClient()\n",
    "ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "for hostname in client_names:\n",
    "    ssh.connect(credential_dict[hostname]['primary_ip_address'],\n",
    "                username=cmd_params['user_name'], \n",
    "                password=cmd_params['user_password'])\n",
    "    stdin, stdout, stderr = ssh.exec_command(cmd)\n",
    "    stdout_lines = stdout.readlines()\n",
    "    stderr_lines = stderr.readlines()\n",
    "    primary_ip_address = credential_dict[hostname]['primary_ip_address']\n",
    "    setup_streams[primary_ip_address]['user'] = {}\n",
    "    setup_streams[primary_ip_address]['user']['stdout'] = ''.join(stdout_lines)\n",
    "    setup_streams[primary_ip_address]['user']['stderr'] = ''.join(stderr_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setup commands have completed we can `ssh` into any of the cluster nodes, e.g. the NFS server one, by following the printed line instruction: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type \"ssh user@169.55.169.150\" at a terminal and input \"user\" as password when prompted\n"
     ]
    }
   ],
   "source": [
    "ssh_login_template = 'Type \"ssh %s@%s\" at a terminal and input \"%s\" as password when prompted'\n",
    "\n",
    "print ssh_login_template % (cmd_params['user_name'], \n",
    "                            credential_dict[server_name]['primary_ip_address'], \n",
    "                            cmd_params['user_password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the cloud cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As soon as we login it, it would be convenient to have a small text file with the short hostnames of the machines we intend to use in our MPI runs. In our case a file `hosts` containing these 3 lines would suffice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "node00\n",
    "node01\n",
    "node02\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this works. First let's do passwordless `ssh` to `node01` and `node02` from the front-end node `node00`: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ssh node01\n",
    "exit\n",
    "\n",
    "ssh node02\n",
    "exit\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now print the hostname using either the linux command or a python package for this. Note that we ask for 6 processes (that is twice the number of launched machines) and then the MPI runtime will ensure that 2 processes per server are run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpirun -np 6 -f hosts hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpirun -np 6 -f hosts python -c \"import socket; print socket.gethostname()\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPI runs from the command line: libSkylark-based tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download and extract a tarball of data we'll need as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wget  https://www.dropbox.com/s/0ilbyeem2ihmvzw/data.tar.gz\n",
    "tar -xvzf data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can try the examples in \n",
    "http://xdata-skylark.github.io/libskylark/docs/stable/sphinx/quick_start.html#command-line-usage.\n",
    "\n",
    "We use all cloud cluster machines in our MPI runs and use 2 processes per machine - 6 MPI processes total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpirun -np 6 -f hosts skylark_svd -k 10 --prefix usps data/usps.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "user@node00:~$ mpirun -np 6 -f hosts skylark_svd -k 10 --prefix usps data/usps.train\n",
    "Reading the matrix... took 3.41e+00 sec\n",
    "Computing approximate SVD...Took 2.29e+00 sec\n",
    "Writing results...took 1.54e-01 sec\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpirun -np 6 -f hosts skylark_linear data/cpu.train cpu.sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "user@node00:~$ mpirun -np 6 -f hosts skylark_linear data/cpu.train cpu.sol\n",
    "Reading the matrix... took 1.28e-01 sec\n",
    "Solving the least squares...Took 3.17e-01 sec\n",
    "Writing results...took 6.23e-04 sec\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpirun -np 6 -f hosts skylark_krr -a 1 -k 0 -g 10 -f 1000 --model model data/usps.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "user@node00:~$ mpirun -np 6 -f hosts skylark_krr -a 1 -k 0 -g 10 -f 1000 --model model data/usps.train\n",
    "# Generated using kernel_regression using the following command-line:\n",
    "#       skylark_krr -a 1 -k 0 -g 10 -f 1000 --model model data/usps.train\n",
    "# Number of ranks is 6\n",
    "Reading the matrix... took 3.06e+00 sec\n",
    "Training...\n",
    "        Dummy coding... took 8.92e-02 sec\n",
    "        Solving...\n",
    "                Computing kernel matrix... took 3.21e+00 sec\n",
    "                Creating precoditioner...\n",
    "                        Applying random features transform... took 1.88e+00 sec\n",
    "                        Computing covariance matrix... took 6.55e+00 sec\n",
    "                        Factorizing... took 5.37e-01 sec\n",
    "                        Prepare factor... took 2.90e+00 sec\n",
    "                Took 1.19e+01 sec\n",
    "                Solving linear equation...\n",
    "                        CG: Iteration 0, Relres = 1.52e+00, 0 rhs converged\n",
    "                        CG: Iteration 10, Relres = 3.59e-01, 0 rhs converged\n",
    "                        CG: Iteration 20, Relres = 1.28e-01, 0 rhs converged\n",
    "                        CG: Iteration 30, Relres = 4.19e-02, 0 rhs converged\n",
    "                        CG: Iteration 40, Relres = 2.18e-02, 0 rhs converged\n",
    "                        CG: Iteration 50, Relres = 9.09e-03, 0 rhs converged\n",
    "                        CG: Iteration 60, Relres = 3.60e-03, 0 rhs converged\n",
    "                        CG: Iteration 70, Relres = 1.57e-03, 2 rhs converged\n",
    "                        CG: Iteration 80, Relres = 9.98e-04, 7 rhs converged\n",
    "                        CG: Iteration 85, Relres = 5.17e-04, 10 rhs converged\n",
    "                        CG: Convergence!\n",
    "                Took 2.80e+01 sec\n",
    "        Solve took 4.31e+01 sec\n",
    "Training took 4.32e+01 sec\n",
    "Saving model... took 1.21e-01 sec\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpirun -np 6 -f hosts skylark_krr --outputfile output --model model usps.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "user@node00:~$ mpirun -np 6 -f hosts skylark_krr --outputfile output --model model usps.test\n",
    "# Generated using kernel_regression using the following command-line:\n",
    "#       skylark_krr --outputfile output --model model usps.test\n",
    "# Number of ranks is 6\n",
    "Reading the matrix... took 1.90e-04 sec\n",
    "Training...\n",
    "        Dummy coding... took 1.14e-03 sec\n",
    "        Solving...\n",
    "                Computing kernel matrix... took 4.68e-03 sec\n",
    "                Creating precoditioner...\n",
    "                        Applying random features transform... took 2.62e-04 sec\n",
    "                        Computing covariance matrix... took 5.35e-03 sec\n",
    "                        Factorizing... took 2.05e+00 sec\n",
    "                        Prepare factor... took 1.09e+00 sec\n",
    "                Took 3.16e+00 sec\n",
    "                Solving linear equation...\n",
    "                        CG: Iteration 0, Relres = -nan, 0 rhs converged\n",
    "                        CG: Convergence!\n",
    "                Took 3.36e-03 sec\n",
    "        Solve took 3.17e+00 sec\n",
    "Training took 3.17e+00 sec\n",
    "Saving model... took 6.83e-04 sec\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpirun -np 6 -f hosts skylark_ml -g 10 -k 1 -l 2 -i 30 -f 1000 --trainfile data/usps.train --valfile data/usps.test --modelfile model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# [shortened output]\n",
    "user@node00:~$ mpirun -np 6 -f hosts skylark_ml -g 10 -k 1 -l 2 -i 30 -f 1000 --trainfile data/usps.train --valfile data/usps.test --modelfile model\n",
    "# Generated using skylark_mlusing the following command-line:\n",
    "#       skylark_ml -g 10 -k 1 -l 2 -i 30 -f 1000 --trainfile data/usps.train --valfile data/usps.test --modelfile model\n",
    "#\n",
    "# Regression? = False\n",
    "# Training File = data/usps.train\n",
    "# Model File = model\n",
    "# Validation File = data/usps.test\n",
    "# Test File =\n",
    "# File Format = 0\n",
    "# Loss function = 2 (Hinge Loss (SVMs))\n",
    "# Regularizer = 0 (No Regularizer)\n",
    "# Kernel = 1 (Gaussian)\n",
    "# Kernel Parameter = 10\n",
    "# Second Kernel Parameter = 0\n",
    "# Third Kernel Parameter = 1\n",
    "# Regularization Parameter = 0\n",
    "# Maximum Iterations = 30\n",
    "# Tolerance = 0.001\n",
    "# rho = 1\n",
    "# Seed = 12345\n",
    "# Random Features = 1000\n",
    "# Cache transforms? = False\n",
    "# Use fast, if availble? = False\n",
    "# Sequence = 0 (Monte Carlo)\n",
    "# Number of feature partitions = 1\n",
    "# Threads = 1\n",
    "# Number of MPI Processes = 6\n",
    "Mode: Training. Loading data...\n",
    "Reading from file data/usps.train\n",
    "Reading and distributing chunk 0 to 7290 (7291 elements )\n",
    "Read Matrix with dimensions: 7291 by 256 (3.03376secs)\n",
    "Loading validation data.\n",
    "Reading from file data/usps.test\n",
    "Reading and distributing chunk 0 to 2006 (2007 elements )\n",
    "Read Matrix with dimensions: 2007 by 256 (0.783422secs)\n",
    "iteration 1 objective 80201 accuracy 0.00 time 1.82563 seconds\n",
    "iteration 2 objective 80201 accuracy 0.00 time 2.38801 seconds\n",
    "iteration 3 objective 16334.1 accuracy 92.87 time 2.94534 seconds\n",
    "iteration 4 objective 2574.06 accuracy 93.02 time 3.49865 seconds\n",
    "...\n",
    "iteration 28 objective 735.573 accuracy 94.67 time 16.8254 seconds\n",
    "iteration 29 objective 716.133 accuracy 94.67 time 17.3821 seconds\n",
    "iteration 30 objective 697.646 accuracy 94.72 time 17.9359 seconds\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpirun -np 6 -f hosts skylark_ml --outputfile output --testfile data/usps.test --modelfile model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "user@node00:~$ mpirun -np 6 -f hosts skylark_ml --outputfile output --testfile data/usps.test --modelfile model\n",
    "Mode: Predicting (from file). Loading data...\n",
    "# Generated using skylark_mlusing the following command-line:\n",
    "#       skylark_ml --outputfile output --testfile data/usps.test --modelfile model\n",
    "#\n",
    "# Regression? = False\n",
    "# Training File =\n",
    "# Model File = model\n",
    "# Validation File =\n",
    "# Test File = data/usps.test\n",
    "# File Format = 0\n",
    "# Loss function = 0 (Squared Loss)\n",
    "# Regularizer = 0 (No Regularizer)\n",
    "# Kernel = 0 (Linear)\n",
    "# Kernel Parameter = 1\n",
    "# Second Kernel Parameter = 0\n",
    "# Third Kernel Parameter = 1\n",
    "# Regularization Parameter = 0\n",
    "# Maximum Iterations = 20\n",
    "# Tolerance = 0.001\n",
    "# rho = 1\n",
    "# Seed = 12345\n",
    "# Random Features = 0\n",
    "# Cache transforms? = False\n",
    "# Use fast, if availble? = False\n",
    "# Sequence = 0 (Monte Carlo)\n",
    "# Number of feature partitions = 1\n",
    "# Threads = 1\n",
    "# Number of MPI Processes = 6\n",
    "Reading from file data/usps.test\n",
    "Reading and distributing chunk 0 to 2006 (2007 elements )\n",
    "Read Matrix with dimensions: 2007 by 256 (0.785275secs)\n",
    "Error rate: 5.18%\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpirun -np 6 -f hosts skylark_community --graphfile data/two_triangles --seed A1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "user@node00:~$ mpirun -np 6 -f hosts skylark_community --graphfile data/two_triangles --seed A1\n",
    "Reading the adjacency matrix... Reading the adjacency matrix... Reading the adjacency matrix...\n",
    "\n",
    "\n",
    "Finished reading... Reading the adjacency matrix... Reading the adjacency matrix...\n",
    "\n",
    "Finished reading... Finished reading... took took 1.45e-03 sec\n",
    "Finished reading... 1.49e-03 sec\n",
    "Reading the adjacency matrix...\n",
    "Analysis complete! Took Finished reading... 9.35e-04 sec\n",
    "Cluster found:Analysis complete! Took\n",
    "A3took took 2.19e-032.21e-03 sec\n",
    " sec\n",
    "Finished reading... took 5.02e-04Analysis complete! Took  A2 A1 Analysis complete! Took\n",
    "1.16e-03Conductivity =  sec\n",
    "0.142857Cluster found:8.71e-04\n",
    "\n",
    "A3 sec\n",
    " sec\n",
    "9.60e-04Cluster found:\n",
    " sec\n",
    "A3A2 Cluster found:A2\n",
    "A1A1 A3\n",
    " Conductivity =  0.142857\n",
    "\n",
    "A2 Conductivity = A10.142857\n",
    "\n",
    "took 6.01e-03 sec\n",
    "Conductivity = 0.142857\n",
    "Analysis complete! Took 6.14e-03 sec\n",
    "Cluster found:\n",
    "A3 A2 A1\n",
    "Conductivity = 0.142857\n",
    "Analysis complete! Took 6.83e-03 sec\n",
    "Cluster found:\n",
    "A3 A2 A1\n",
    "Conductivity = 0.142857\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skylark_graph_se -k 2 data/two_triangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "user@node00:~$ skylark_graph_se -k 2 data/two_triangles\n",
    "Reading the graph... took 1.87e-04 sec\n",
    "Computing embeddings... took 3.42e-03 sec\n",
    "Writing results... took 2.75e-04 sec\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive MPI runs in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting things up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's install first the package enabling interactive MPI sessions in jupyter - which is already installed as part of the cluster setup process. Then we start a notebook server **at any of the cloud cluster nodes** and keep the token that is printed handy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "conda install -y ipyparallel\n",
    "jupyter notebook --no-browser --port=12345\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "Then we open a terminal **at our laptop** and build an ssh tunnel to the jupyter notebook server we just started at the cloud cluster. *In what follows `169.55.169.150` will be the IP of the node where the jupyter notebook server is running:*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ssh -f -N -L3333:localhost:12345 user@169.55.169.150\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we open a local browser, point it to http://localhost:3333 in our case, input the token and we are ready to start a notebook (New > Python2) and two terminal sessions, which will be connected to the cluster node where the notebook server was started (New > Terminal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can also start one controller and three engines from within the notebook terminal sessions. The engines are basically network-enabled Python kernels (can receive/send input out through network connections) and in our case - since they are launched through MPI launcher - they can also be involved in an (interactive) MPI computation, e.g. using mpi4py Python package. These engines register with the controller process we start separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ipcontroller --ip=169.55.169.150\n",
    "mpirun -np 3 -f hosts ipengine --mpi=mpi4py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After connections are established the log messages in the two terminal sessions will look like (shortened outputs):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "user@node00:~$ ipcontroller --ip=169.55.169.150\n",
    "2017-02-06 18:36:47.058 [IPControllerApp] Hub listening on tcp://169.55.169.150:49374 for registration.\n",
    "2017-02-06 18:36:47.061 [IPControllerApp] Hub using DB backend: 'DictDB'\n",
    "2017-02-06 18:36:47.315 [IPControllerApp] hub::created hub\n",
    "2017-02-06 18:36:47.338 [IPControllerApp] writing connection info to /shared/.ipython/profile_default/security/ipcontroller-client.j\n",
    "son\n",
    "...\n",
    "2017-02-06 18:38:44.350 [IPControllerApp] registration::finished registering engine 2:2d6d9a64-aa11-4199-b10b-58df4f56258b\n",
    "2017-02-06 18:38:44.351 [IPControllerApp] engine::Engine Connected: 2\n",
    "```\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "user@node00:~$ mpirun -np 3 -f hosts ipengine --mpi=mpi4py\n",
    "2017-02-06 18:38:36.186 [IPEngineApp] Initializing MPI:\n",
    "2017-02-06 18:38:36.187 [IPEngineApp] from mpi4py import MPI as mpi\n",
    "mpi.size = mpi.COMM_WORLD.Get_size()\n",
    "mpi.rank = mpi.COMM_WORLD.Get_rank()\n",
    "...\n",
    "2017-02-06 18:38:41.080 [IPEngineApp] Starting to monitor the heartbeat signal from the hub every 3010 ms.\n",
    "2017-02-06 18:38:41.110 [IPEngineApp] Completed registration with id 1\n",
    "2017-02-06 18:38:41.112 [IPEngineApp] Completed registration with id 2\n",
    "2017-02-06 18:38:41.089 [IPEngineApp] Completed registration with id 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive MPI examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see the interactive MPI computation session in action. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook we can then enter the following snippet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from ipyparallel import Client\n",
    "import numpy as np\n",
    "\n",
    "c = Client()\n",
    "view = c[:]\n",
    "view.activate()\n",
    "view.scatter('a',np.arange(16,dtype='float'))\n",
    "view['a']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and it should output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[array([ 0.,  1.,  2.,  3.,  4.,  5.]),\n",
    " array([  6.,   7.,   8.,   9.,  10.]),\n",
    " array([ 11.,  12.,  13.,  14.,  15.])]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even revisit the \"hostname\" example above in an interactive setting by entering in the notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "view.execute('import socket; host=socket.gethostname()')\n",
    "view['host']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and it should output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "['node02.skylark.com', 'node01.skylark.com', 'node00.skylark.com']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also enter the following snippet in a file (e.g. `sketch_example.py` using the editor that comes with the notebook, it will be saved at the cloud cluster node):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```python\n",
    "# sketch_example.py\n",
    "\n",
    "import El\n",
    "from skylark import sketch\n",
    "A = El.DistMatrix()\n",
    "El.Uniform(A, 10, 10)\n",
    "S = sketch.FJLT(10, 4) \n",
    "SA = S * A\n",
    "sketched_matrix = [[SA.Get(i, j) for j in range(10)] for i in range(4)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can run this over the cluster and get 3 identical 4 x 10 sketched matrices in the `sketched_matrix` variable (for each of the nodes); the view we get is a list of 3 nested lists which is shortened below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "view.run('sketch_example.py')\n",
    "view['sketched_matrix']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "[[[-0.3101992999959424,\n",
    "   0.6483628527959093,\n",
    "   0.1958483439974383,\n",
    "   0.4446715646290061,\n",
    "   0.9886868537882584,\n",
    "   -0.26960721013585903,\n",
    "   -0.9024278447032668,\n",
    "   1.0498253423008397,\n",
    "   -0.04086442729353306,\n",
    "   -1.957760961341717],\n",
    "  [-1.339483931706679,\n",
    "   0.3757472310582834,\n",
    "   ...\n",
    "   -0.3312500853340126,\n",
    "   0.46249798425486943,\n",
    "   -1.9693807622535253,\n",
    "   0.3678465840888163]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Terminating the cloud cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are done using the cloud cluster we can terminate all instances.\n",
    "\n",
    "** Doing so we stop charging, so we should always do this at the end of our computing session.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for nodename in nodename_list:\n",
    "    vs_manager.cancel_instance(vsi_dict[nodename]['id'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
